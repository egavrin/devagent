# OpenAI Direct API models (without provider prefix)
provider = "openai"
base_url = "https://api.openai.com/v1"

[gpt-4o]
context_window = 128000
response_headroom = 16000
tokenizer = "o200k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = true

[gpt-4o-mini]
context_window = 128000
response_headroom = 16000
tokenizer = "o200k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = true

[gpt-4o-2024-11-20]
context_window = 128000
response_headroom = 16000
tokenizer = "o200k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = true

[gpt-4o-2024-08-06]
context_window = 128000
response_headroom = 16000
tokenizer = "o200k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = true

[gpt-4-turbo]
context_window = 128000
response_headroom = 4000
tokenizer = "cl100k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = true

[gpt-4-turbo-preview]
context_window = 128000
response_headroom = 4000
tokenizer = "cl100k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = true

[gpt-4]
context_window = 8192
response_headroom = 1000
tokenizer = "cl100k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = true

[gpt-4-32k]
context_window = 32768
response_headroom = 4000
tokenizer = "cl100k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = true

[gpt-3.5-turbo]
context_window = 16385
response_headroom = 4000
tokenizer = "cl100k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = true

[gpt-3.5-turbo-16k]
context_window = 16385
response_headroom = 4000
tokenizer = "cl100k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = true

[o1]
context_window = 200000
response_headroom = 100000
tokenizer = "o200k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = false

[o1-mini]
context_window = 128000
response_headroom = 65000
tokenizer = "o200k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = false

[o1-preview]
context_window = 128000
response_headroom = 32000
tokenizer = "o200k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = false

[o3-mini]
context_window = 200000
response_headroom = 100000
tokenizer = "o200k_base"
supports_tools = true
supports_parallel_tools = true
supports_temperature = false
